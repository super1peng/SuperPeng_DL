{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST Ready\n"
     ]
    }
   ],
   "source": [
    "# 将数据导入\n",
    "mnist  = input_data.read_data_sets('./data', one_hot=True)\n",
    "trainimg = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabel = mnist.test.labels\n",
    "print(\"MNIST Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数初始化操作\n",
    "n_input = 784\n",
    "n_output = 10\n",
    "weights = {\n",
    "    'wc1':tf.Variable(tf.random_normal([3,3,1,64], stddev=0.1)), # 第一个卷积层  因为原始的是灰度图 所以第三维为1\n",
    "    'wc2':tf.Variable(tf.random_normal([3,3,64,128], stddev=0.1)), # 第二个卷积层\n",
    "    'wd1':tf.Variable(tf.random_normal([7*7*128,1024], stddev=0.1)), # 第一个全连接层\n",
    "    'wd2':tf.Variable(tf.random_normal([1024, n_output], stddev=0.1)), # 第二个全连接层\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1':tf.Variable(tf.random_normal([64], stddev=0.1)),\n",
    "    'bc2':tf.Variable(tf.random_normal([128], stddev=0.1)),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024], stddev=0.1)),\n",
    "    'bd2':tf.Variable(tf.random_normal([n_output], stddev=0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Ready\n"
     ]
    }
   ],
   "source": [
    "# 卷积+池化\n",
    "def conv_basic(_input, _w, _b, _keepratio): # keepratio drop层每次训练保留的比率\n",
    "    # 输入\n",
    "    _input_r = tf.reshape(_input, shape=[-1,28,28,1])   # 输入数据的格式： batch_size*high*weight*depth\n",
    "    # 第一层卷积操作\n",
    "    _conv1 = tf.nn.conv2d(_input_r, _w['wc1'], strides=[1,1,1,1], padding='SAME') # stride 步幅\n",
    "    _conv1 = tf.nn.relu(tf.nn.bias_add(_conv1,_b['bc1'])) # relu激活函数\n",
    "    _pool1 = tf.nn.max_pool(_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # 使用max进行池化操作\n",
    "    _pool_dr1 = tf.nn.dropout(_pool1,_keepratio) # dropout层\n",
    "    \n",
    "    \n",
    "    # 第二层卷积操作\n",
    "    _conv2 = tf.nn.conv2d(_pool_dr1, _w['wc2'], strides=[1,1,1,1], padding='SAME') # stride 步幅\n",
    "    _conv2 = tf.nn.relu(tf.nn.bias_add(_conv2,_b['bc2'])) # relu激活函数\n",
    "    _pool2 = tf.nn.max_pool(_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # 使用max进行池化操作\n",
    "    _pool_dr2 = tf.nn.dropout(_pool2,_keepratio) # dropout层\n",
    "    \n",
    "    # 将多维转化为1维\n",
    "    _dense1 = tf.reshape(_pool_dr2, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    # 第一个全连接层\n",
    "    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "    \n",
    "    # 第一个全连接层\n",
    "    _out = tf.add(tf.matmul(_fc_dr1,_w['wd2']), _b['bd2'])\n",
    "    \n",
    "    # return\n",
    "    out = {\n",
    "        'input_r':_input_r, 'conv1':_conv1, 'pool1':_pool1,'pool_dr1':_pool_dr1,\n",
    "        'conv2':_conv2, 'pool2':_pool2,'pool_dr2':_pool_dr2,'dense1':_dense1,\n",
    "        'fc1':_fc1,'fc_dr1':_fc_dr1,'out':_out\n",
    "    }\n",
    "    \n",
    "    return out\n",
    "print(\"CNN Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-114cf0fb8b7d>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "GRAPH READY\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None, n_input])\n",
    "y = tf.placeholder(tf.float32,[None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "# tensorflow一些操作\n",
    "_pred = conv_basic(x, weights, biases, keepratio)['out'] # 预测函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_pred, labels=y)) # 计算损失函数\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost) # 优化器\n",
    "\n",
    "_corr = tf.equal(tf.argmax(_pred, 1), tf.argmax(y, 1))  \n",
    "accr = tf.reduce_mean(tf.cast(_corr,tf.float32)) # 计算准确度\n",
    "\n",
    "init = tf.global_variables_initializer() # 初始化操作\n",
    "\n",
    "# 模型的保存相关设置\n",
    "# SAVER\n",
    "save_step = 1 # 每epoch就保存一次\n",
    "saver = tf.train.Saver(max_to_keep=3)   # 保存的参数的最大范围  设置为保存3次迭代的参数\n",
    "\n",
    "print(\"GRAPH READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = 1\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/015 cost: 5.622116637\n",
      "Traning accuracy: 0.187500000\n",
      "Epoch: 001/015 cost: 2.898527050\n",
      "Traning accuracy: 0.375000000\n",
      "Epoch: 002/015 cost: 1.442147481\n",
      "Traning accuracy: 0.562500000\n",
      "Epoch: 003/015 cost: 1.255333036\n",
      "Traning accuracy: 0.500000000\n",
      "Epoch: 004/015 cost: 1.204416513\n",
      "Traning accuracy: 0.750000000\n",
      "Epoch: 005/015 cost: 1.177002358\n",
      "Traning accuracy: 0.937500000\n",
      "Epoch: 006/015 cost: 0.976815331\n",
      "Traning accuracy: 0.562500000\n",
      "Epoch: 007/015 cost: 0.992108470\n",
      "Traning accuracy: 0.687500000\n",
      "Epoch: 008/015 cost: 0.922193468\n",
      "Traning accuracy: 0.750000000\n",
      "Epoch: 009/015 cost: 0.803165436\n",
      "Traning accuracy: 0.875000000\n",
      "Epoch: 010/015 cost: 0.839902925\n",
      "Traning accuracy: 0.750000000\n",
      "Epoch: 011/015 cost: 0.714129961\n",
      "Traning accuracy: 0.625000000\n",
      "Epoch: 012/015 cost: 0.617662951\n",
      "Traning accuracy: 0.750000000\n",
      "Epoch: 013/015 cost: 0.654907161\n",
      "Traning accuracy: 0.750000000\n",
      "Epoch: 014/015 cost: 0.611684394\n",
      "Traning accuracy: 1.000000000\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 16\n",
    "display_step = 1\n",
    "if do_train == 1:\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = 10\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optm, feed_dict={x:batch_xs,y:batch_ys, keepratio:0.7 })\n",
    "            # 计算平均误差\n",
    "            avg_cost += sess.run(cost, feed_dict={x:batch_xs, y:batch_ys, keepratio:1.})/total_batch\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "            train_acc =sess.run(accr, feed_dict={x:batch_xs, y:batch_ys, keepratio:1. })\n",
    "            print(\"Traning accuracy: %.9f\" % (train_acc))\n",
    "\n",
    "#             test_acc = sess.run(accr, feed_dict={x:testimg, y:testlabel, keepratio:1. })\n",
    "#             print(\"Test accuracy: %.3f\" % (test_acc))\n",
    "        \n",
    "        # 进行模型的保存操作\n",
    "        if epoch % save_step == 0:\n",
    "            saver.save(sess, \"save/nets/cnn_mnist_basic.ckpt-\" + str(epoch))\n",
    "    print(\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = 0\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/nets/cnn_mnist_basic.ckpt-14\n",
      " TEST ACCURACY: 0.865\n"
     ]
    }
   ],
   "source": [
    "if do_train == 0:\n",
    "    epoch = training_epochs-1\n",
    "    saver.restore(sess, \"save/nets/cnn_mnist_basic.ckpt-\" + str(epoch))\n",
    "    \n",
    "    test_acc = sess.run(accr, feed_dict={x: testimg, y: testlabel, keepratio:1.})\n",
    "    print (\" TEST ACCURACY: %.3f\" % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
