{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络的简单结构\n",
    "# 输入层： batch_size * 784\n",
    "# 第一个卷积层conv1 3*3*1 filter设置为64\n",
    "# 池化层： 窗口大小 2*2\n",
    "# 第二层卷积层conv2 3*3*64  filter设置为128\n",
    "# 池化层： 窗口大小 2*2\n",
    "# 第一层全连接层： 1024\n",
    "# 第二层全连接层： 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照上述模型初始化卷积神经网络的参数\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n",
      "MNIST Ready\n"
     ]
    }
   ],
   "source": [
    "# 将数据导入\n",
    "mnist  = input_data.read_data_sets('./data', one_hot=True)\n",
    "trainimg = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabel = mnist.test.labels\n",
    "print(\"MNIST Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数初始化操作\n",
    "n_input = 784\n",
    "n_output = 10\n",
    "weights = {\n",
    "    'wc1':tf.Variable(tf.random_normal([3,3,1,64], stddev=0.1)), # 第一个卷积层  因为原始的是灰度图 所以第三维为1\n",
    "    'wc2':tf.Variable(tf.random_normal([3,3,64,128], stddev=0.1)), # 第二个卷积层\n",
    "    'wd1':tf.Variable(tf.random_normal([7*7*128,1024], stddev=0.1)), # 第一个全连接层\n",
    "    'wd2':tf.Variable(tf.random_normal([1024, n_output], stddev=0.1)), # 第二个全连接层\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1':tf.Variable(tf.random_normal([64], stddev=0.1)),\n",
    "    'bc2':tf.Variable(tf.random_normal([128], stddev=0.1)),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024], stddev=0.1)),\n",
    "    'bd2':tf.Variable(tf.random_normal([n_output], stddev=0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Ready\n"
     ]
    }
   ],
   "source": [
    "# 卷积+池化\n",
    "def conv_basic(_input, _w, _b, _keepratio): # keepratio drop层每次训练保留的比率\n",
    "    # 输入\n",
    "    _input_r = tf.reshape(_input, shape=[-1,28,28,1])   # 输入数据的格式： batch_size*high*weight*depth\n",
    "    # 第一层卷积操作\n",
    "    _conv1 = tf.nn.conv2d(_input_r, _w['wc1'], strides=[1,1,1,1], padding='SAME') # stride 步幅\n",
    "    _conv1 = tf.nn.relu(tf.nn.bias_add(_conv1,_b['bc1'])) # relu激活函数\n",
    "    _pool1 = tf.nn.max_pool(_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # 使用max进行池化操作\n",
    "    _pool_dr1 = tf.nn.dropout(_pool1,_keepratio) # dropout层\n",
    "    \n",
    "    \n",
    "    # 第二层卷积操作\n",
    "    _conv2 = tf.nn.conv2d(_pool_dr1, _w['wc2'], strides=[1,1,1,1], padding='SAME') # stride 步幅\n",
    "    _conv2 = tf.nn.relu(tf.nn.bias_add(_conv2,_b['bc2'])) # relu激活函数\n",
    "    _pool2 = tf.nn.max_pool(_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # 使用max进行池化操作\n",
    "    _pool_dr2 = tf.nn.dropout(_pool2,_keepratio) # dropout层\n",
    "    \n",
    "    # 将多维转化为1维\n",
    "    _dense1 = tf.reshape(_pool_dr2, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    # 第一个全连接层\n",
    "    _fc1 = tf.nn.relu(tf.add(tf.matmul(_dense1, _w['wd1']), _b['bd1']))\n",
    "    _fc_dr1 = tf.nn.dropout(_fc1, _keepratio)\n",
    "    \n",
    "    # 第一个全连接层\n",
    "    _out = tf.add(tf.matmul(_fc_dr1,_w['wd2']), _b['bd2'])\n",
    "    \n",
    "    # return\n",
    "    out = {\n",
    "        'input_r':_input_r, 'conv1':_conv1, 'pool1':_pool1,'pool_dr1':_pool_dr1,\n",
    "        'conv2':_conv2, 'pool2':_pool2,'pool_dr2':_pool_dr2,'dense1':_dense1,\n",
    "        'fc1':_fc1,'fc_dr1':_fc_dr1,'out':_out\n",
    "    }\n",
    "    \n",
    "    return out\n",
    "print(\"CNN Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-fba604abceaf>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "GRAPH READY\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None, n_input])\n",
    "y = tf.placeholder(tf.float32,[None, n_output])\n",
    "keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "# tensorflow一些操作\n",
    "_pred = conv_basic(x, weights, biases, keepratio)['out'] # 预测函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_pred, labels=y)) # 计算损失函数\n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost) # 优化器\n",
    "\n",
    "_corr = tf.equal(tf.argmax(_pred, 1), tf.argmax(y, 1))  \n",
    "accr = tf.reduce_mean(tf.cast(_corr,tf.float32)) # 计算准确度\n",
    "\n",
    "init = tf.global_variables_initializer() # 初始化操作\n",
    "\n",
    "print(\"GRAPH READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/015 cost: 8.562921381\n",
      "Traning accuracy: 0.250000000\n",
      "Test accuracy: 0.283\n",
      "Epoch: 001/015 cost: 2.753999901\n",
      "Traning accuracy: 0.062500000\n",
      "Test accuracy: 0.263\n",
      "Epoch: 002/015 cost: 1.695076704\n",
      "Traning accuracy: 0.437500000\n",
      "Test accuracy: 0.382\n",
      "Epoch: 003/015 cost: 1.660584903\n",
      "Traning accuracy: 0.562500000\n",
      "Test accuracy: 0.566\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 16\n",
    "display_step = 1\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    # 其实这里应该等于：\n",
    "    # total_batch int(mnist.train.num_example / batchsize)\n",
    "    total_batch = 10\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        sess.run(optm, feed_dict={x:batch_xs,y:batch_ys, keepratio:0.7 })\n",
    "        \n",
    "        # 计算平均误差\n",
    "        avg_cost += sess.run(cost, feed_dict={x:batch_xs, y:batch_ys, keepratio:1.})/total_batch\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        train_acc =sess.run(accr, feed_dict={x:batch_xs, y:batch_ys, keepratio:1. })\n",
    "        print(\"Traning accuracy: %.9f\" % (train_acc))\n",
    "        \n",
    "        test_acc = sess.run(accr, feed_dict={x:testimg, y:testlabel, keepratio:1. })\n",
    "        print(\"Test accuracy: %.3f\" % (test_acc))\n",
    "    \n",
    "print(\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
